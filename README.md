# Trulia_House_Prices_Scraping

The project explores the issue of housing affordability in two of California's largest cities, Los
Angeles and San Francisco. To determine which city is more expensive to live in, the article
considers various factors such as the type of house, number of bedrooms and bathrooms,
location, and neighborhood population. In addition, the article defines affordability based on the
expense of purchasing a home relative to the median household income in that area.
To obtain the data necessary for the analysis, the authors turned to Trulia, an online real estate
marketplace widely used in the United States. The authors explain that they chose Trulia due to
its comprehensive data on housing, including price, number of bedrooms and bathrooms,
property type, and address. They also noted that Trulia is a popular website for people searching
for homes, making it an excellent source for representative data.
To extract the data, the authors utilized the Beautiful Soup package in Python, a library that
simplifies the process of scraping information from web pages. They also used the Position Stack
API and Precisely API to obtain latitude and longitude data and determine neighborhoods based
on that data.
